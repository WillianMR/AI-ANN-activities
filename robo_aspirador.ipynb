{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2892e366",
   "metadata": {},
   "source": [
    "\n",
    "# Simulação de Robô Aspirador - Inteligência Artificial e Agentes\n",
    "\n",
    "Este notebook apresenta a simulação de um robô aspirador, utilizando agentes inteligentes para decidir a limpeza\n",
    "do ambiente com base em condições predefinidas e ações possíveis.\n",
    "\n",
    "## Conteúdos:\n",
    "1. Modelagem do Ambiente e Estados\n",
    "2. Decisões e Ações do Robô Aspirador\n",
    "3. Análise do Desempenho da Simulação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbPLWLsJesH7"
   },
   "source": [
    "Código referente ao modelo de \"ambiente e agente\" da disciplina de Inteligência Artificial no programa de Mestrado em Computação Aplicada. É desenvolvido um protótipo de \"robô agente\" responsável por limpar um ambiente.\n",
    "O robô pode apenas se movimentar para esquerda ou direita, e aspirar ou não."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7Viu_AHx3vF"
   },
   "source": [
    "Para definir as classes temos as seguintes restrições:\n",
    "\n",
    "\n",
    "*   A medida de desempenho ofereça o prêmio de um ponto para cada quadrado limpo em cada período de tempo, ao longo de um “tempo de vida” de 1.000 passos de tempo.\n",
    "*   A “geografia” do ambiente seja conhecida a priori, mas a distribuição da sujeira e a posição inicial do agente não sejam previamente conhecidas.\n",
    "*   Quadrados limpos permanecem limpos, e a aspiração limpa o quadrado atual. As ações Esquerda e Direita movem o agente para a esquerda e para a direita, exceto quando isso leva o agente para fora do ambiente; nesse\n",
    "caso, o agente permanece onde está.\n",
    "*   As únicas ações disponíveis são Esquerda, Direita e Aspirar.\n",
    "*   O agente percebe corretamente sua posição e se essa posição contém sujeira.\n",
    "\n",
    "1) Finalizar o exercício de implementação do robô-aspirador usando como métrica:\n",
    "(a) critério de parada: todos os quadriculados do ambiente estão limpos e\n",
    "(b) um score de gasto energético a ser minimizado (onde os custo energético das ações são:\n",
    "  (i) leitura do sensor de sujeira: 1;\n",
    "  (ii) mover dir/esq: 5;\n",
    "  (iii) aspirar: 10;\n",
    "simular 1000 episódios e calcular a média/desvio-padrão e plotar um gráfico Boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fp6OSthcenEC"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        # instantiate locations and conditions\n",
    "        # 0 indicates  Clean and 1 indicates Dirty\n",
    "        self.locationCondition = {'A': '0', 'B': '0'}\n",
    "\n",
    "        # randomize conditions in locations A and B\n",
    "        self.locationCondition['A'] = random.randint(0, 1)\n",
    "        self.locationCondition['B'] = random.randint(0, 1)\n",
    "\n",
    "\n",
    "class SimpleReflexVacuumAgent(Environment):\n",
    "    def __init__(self, Environment):\n",
    "        print Environment.locationCondition\n",
    "        # Instantiate performance measurement\n",
    "        Score = 0\n",
    "        # place vacuum at random location\n",
    "        vacuumLocation = random.randint(0, 1)\n",
    "        # if vacuum at A\n",
    "        if vacuumLocation == 0:\n",
    "            print \"Vacuum is randomly placed at Location A\"\n",
    "            # and A is Dirty\n",
    "            if Environment.locationCondition['A'] == 1:\n",
    "                print \"Location A is Dirty. \"\n",
    "                # suck and mark clean\n",
    "                Environment.locationCondition['A'] = 0;\n",
    "                Score += 1\n",
    "                print \"Location A has been Cleaned. :D\"\n",
    "\n",
    "                # if B is Dirty\n",
    "                if Environment.locationCondition['B'] == 1:\n",
    "                    print \"Location B is Dirty.\"\n",
    "                    # move to B\n",
    "                    print \"Moving to Location B...\"\n",
    "                    Score -= 1\n",
    "                    # suck and mark clean\n",
    "                    Environment.locationCondition['B'] = 0;\n",
    "                    Score += 1\n",
    "                    print \"Location B has been Cleaned :D.\"\n",
    "            else:\n",
    "\n",
    "                # if B is Dirty\n",
    "                if Environment.locationCondition['B'] == 1:\n",
    "                    print \"Location B is Dirty.\"\n",
    "                    # move to B\n",
    "                    Score -= 1\n",
    "                    print \"Moving to Location B...\"\n",
    "                    # suck and mark clean\n",
    "                    Environment.locationCondition['B'] = 0;\n",
    "                    Score += 1\n",
    "                    print \"Location B has been Cleaned. :D\"\n",
    "\n",
    "        elif vacuumLocation == 1:\n",
    "            print \"Vacuum is randomly placed at Location B. \"\n",
    "            # and B is Dirty\n",
    "            if Environment.locationCondition['B'] == 1:\n",
    "                print \"Location B is Dirty\"\n",
    "                # suck and mark clean\n",
    "                Environment.locationCondition['B'] = 0;\n",
    "                Score += 1\n",
    "                print \"Location B has been Cleaned\"\n",
    "\n",
    "                # if A is Dirty\n",
    "                if Environment.locationCondition['A'] == 1:\n",
    "                    print \"Location A is Dirty\"\n",
    "                    # move to A\n",
    "                    Score -= 1\n",
    "                    print \"Moving to Location A\"\n",
    "                    # suck and mark clean\n",
    "                    Environment.locationCondition['A'] = 0;\n",
    "                    Score += 1\n",
    "                    print \"Location A has been Cleaned\"\n",
    "            else:\n",
    "\n",
    "                # if A is Dirty\n",
    "                if Environment.locationCondition['A'] == 1:\n",
    "                    print \"Location A is Dirty\"\n",
    "                    # move to A\n",
    "                    print \"Moving to Location A\"\n",
    "                    Score -= 1\n",
    "                    # suck and mark clean\n",
    "                    Environment.locationCondition['A'] = 0;\n",
    "                    Score += 1\n",
    "                    print \"Location A has been Cleaned\"\n",
    "        # done cleaning\n",
    "        print Environment.locationCondition\n",
    "        print \"Performance Measurement: \" + str(Score)\n",
    "\n",
    "\n",
    "theEnvironment = Environment()\n",
    "theVacuum = SimpleReflexVacuumAgent(theEnvironment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQ1uU25nKjeT"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Environment(object): # create the environmrnt\n",
    "    def __init__(self):\n",
    "        self.location = ['a', 'b']\n",
    "        self.location_condition = {'a':'0',\n",
    "                                   'b':'0'}\n",
    "        self.vacuum_location = random.choice(self.location)\n",
    "        self.location_condition['a'] = random.randint(0, 1)\n",
    "        self.location_condition['b'] = random.randint(0, 1)\n",
    "\n",
    "class Agent(Environment): # create the agent\n",
    "    def __init__(self, Environment):\n",
    "        print('Vacuum location: ', Environment.vacuum_location) # find the vacuum\n",
    "        print('Location condition: ', Environment.location_condition) # show the condition of the area\n",
    "\n",
    "        count = 0\n",
    "        while count < 2:\n",
    "            # if the area where the vaccum is is dirty, clean it. Otherwise leave it\n",
    "            if Environment.location_condition[Environment.vacuum_location] == 1:\n",
    "                Environment.location_condition[Environment.vacuum_location] = 0\n",
    "                print('Location ', Environment.vacuum_location, ' has been cleaned.')\n",
    "            else:\n",
    "                print('Location ', Environment.vacuum_location, ' is already clean.')\n",
    "\n",
    "            # move to the next location\n",
    "            new_index = Environment.location.index(Environment.vacuum_location) + 1\n",
    "            if new_index == 2:\n",
    "                new_index = 0\n",
    "\n",
    "            Environment.vacuum_location = Environment.location[new_index]\n",
    "            count += 1\n",
    "        print('Finished cleaning :-)')\n",
    "\n",
    "# create the objects\n",
    "environment_object = Environment()\n",
    "agent_object = Agent(environment_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FosTU8q4Km-E"
   },
   "outputs": [],
   "source": [
    "# Agent based on state, action, reward, with sensors, actuators and agent function\n",
    "import time\n",
    "\n",
    "class SimpleReflexVacuumAgent:\n",
    "    def __init__(self, percepts):\n",
    "        self.__state = {}\n",
    "        self.__action = \"\"\n",
    "        self.__performance = 0\n",
    "        self.env_state_in(percepts)\n",
    "\n",
    "    # Sensor (Page 49 - Figure 2.9)\n",
    "    def env_state_in(self, percepts):\n",
    "        self.__state = {\"dirty\": percepts[0] == \"dirty\", \"location\": percepts[1]} # What the world is like now (Page 49 - Figure 2.9)\n",
    "\n",
    "    # Performance measure (Page 37 - Line 5) - Compute reward from environment\n",
    "    def env_reward_in(self, reward):\n",
    "        self.__performance += reward\n",
    "\n",
    "    # Actuator (Page 49 - Figure 2.9)\n",
    "    def agent_action_out(self):\n",
    "        condition_action = lambda x: \"suck\" if x[\"dirty\"] else \"left\" if x[\"location\"] == \"B\" else \"right\" # Condition-action rules (Page 49 - Figure 2.9)\n",
    "        self.__action = condition_action(self.__state) # What action I should do now (Page 49 - Figure 2.9)\n",
    "        return self.__action\n",
    "\n",
    "    def get_performance(self):\n",
    "        return self.__performance\n",
    "\n",
    "    def print_action(self):\n",
    "        print(f\"Vacuum Cleaner: {self.__action}\")\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self, agent_position, rooms_dirty):\n",
    "        self.__rooms_dirty = rooms_dirty\n",
    "        self.__agent_position = agent_position\n",
    "        self.__reward = False\n",
    "\n",
    "    # Receive action from the agent\n",
    "    def agent_action_in(self, action):\n",
    "        if action == \"suck\":\n",
    "            self.__rooms_dirty[self.__agent_position] = \"clean\"\n",
    "            self.__reward = True\n",
    "        else:\n",
    "            self.__agent_position = \"A\" if action == \"left\" else \"B\"\n",
    "\n",
    "    # Send the current state to the agent\n",
    "    def env_state_out(self):\n",
    "        return [self.__rooms_dirty[self.__agent_position], self.__agent_position]\n",
    "\n",
    "    # Compute reward and send it to the agent\n",
    "    def env_reward_out(self):\n",
    "        reward = 1 if self.__reward else 0\n",
    "        self.__reward = False\n",
    "        return reward\n",
    "\n",
    "    def print_state(self):\n",
    "        print(f\"Room A [{self.__rooms_dirty['A']}], Room B [{self.__rooms_dirty['B']}], Agent Position [{self.__agent_position}]\")\n",
    "\n",
    "def simulate(environment_configurations, num_simulations, sleep=0):\n",
    "    performance = []\n",
    "\n",
    "    for config in environment_configurations:\n",
    "        # Setup the environment and agent\n",
    "        rooms_dirty, agent_position = config\n",
    "        env = Environment(agent_position, rooms_dirty)\n",
    "        agent = SimpleReflexVacuumAgent(env.env_state_out())\n",
    "        env.print_state()\n",
    "\n",
    "        # Iterate N times and wait agent-environment changes\n",
    "        for _ in range(num_simulations):\n",
    "            agent.env_state_in(env.env_state_out())       # env:   send state  | agent: get state\n",
    "            env.agent_action_in(agent.agent_action_out()) # agent: send action | env:   get action\n",
    "            agent.env_reward_in(env.env_reward_out())     # env:   send reward | agent: get reward\n",
    "\n",
    "            time.sleep(sleep)\n",
    "            agent.print_action()\n",
    "            time.sleep(sleep)\n",
    "            env.print_state()\n",
    "        time.sleep(sleep)\n",
    "        performance.append(agent.get_performance()) # Save individual performance\n",
    "        print(f\"Performance: {performance[-1]}\")\n",
    "        time.sleep(sleep)\n",
    "        print(\"-\" * 30)\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    average_performance = sum(performance) / len(performance) # Compute average performance\n",
    "    return average_performance, performance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    environment_configurations = [\n",
    "        ({\"A\":\"dirty\", \"B\":\"dirty\"}, \"A\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"clean\"}, \"A\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"dirty\"}, \"A\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"clean\"}, \"A\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"dirty\"}, \"B\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"clean\"}, \"B\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"dirty\"}, \"B\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"clean\"}, \"B\"),\n",
    "    ]\n",
    "\n",
    "    sleep = 1\n",
    "    num_simulations = 4\n",
    "    average_performance, performance = simulate(environment_configurations, num_simulations, sleep)\n",
    "    print(f\"Average Performance: {average_performance} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tSM3cdeaLDPD"
   },
   "outputs": [],
   "source": [
    "# Make with the pseudocode from the page 49\n",
    "import time\n",
    "\n",
    "def interpret_inputs(percepts):\n",
    "    return {\"dirty\": percepts[0] == \"dirty\", \"location\": percepts[1]}\n",
    "\n",
    "def rule_match(state, rules):\n",
    "    return {\"action\": rules(state)}\n",
    "\n",
    "# Code from pseudocode (page 49)\n",
    "def simple_reflex_agent(percepts):\n",
    "    rules = lambda x: \"suck\" if x[\"dirty\"] else \"left\" if x[\"location\"] == \"B\" else \"right\"\n",
    "\n",
    "    state = interpret_inputs(percepts)\n",
    "    rule = rule_match(state, rules)\n",
    "    action = rule[\"action\"]\n",
    "    return action\n",
    "\n",
    "def simulate(environment_configurations, num_simulations, sleep=0):\n",
    "    performance = []\n",
    "    print_state = lambda a,b,pos: print(f\"Room A [{a}], Room B [{b}], Agent Position [{pos}]\")\n",
    "    print_action = lambda act: print(f\"Vacuum Cleaner: {act}\")\n",
    "\n",
    "    for config in environment_configurations:\n",
    "        # Setup the environment and agent\n",
    "        rooms_dirty, agent_position = config\n",
    "        reward = 0\n",
    "        print_state(rooms_dirty['A'], rooms_dirty['B'], agent_position)\n",
    "\n",
    "        # Iterate N times and wait agent-environment changes\n",
    "        for _ in range(num_simulations):\n",
    "            state = [rooms_dirty[agent_position], agent_position] # generate env state\n",
    "            action = simple_reflex_agent(state)                   # generate agent action\n",
    "\n",
    "            if action == \"suck\":\n",
    "                rooms_dirty[agent_position] = \"clean\"\n",
    "                reward += 1 # generate agent reward\n",
    "            else:\n",
    "                agent_position = \"A\" if action == \"left\" else \"B\"\n",
    "\n",
    "            time.sleep(sleep)\n",
    "            print_action(action)\n",
    "            time.sleep(sleep)\n",
    "            print_state(rooms_dirty['A'], rooms_dirty['B'], agent_position)\n",
    "        time.sleep(sleep)\n",
    "        performance.append(reward)\n",
    "        print(f\"Performance: {performance[-1]}\") # Save individual performance\n",
    "        time.sleep(sleep)\n",
    "        print(\"-\" * 30)\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    average_performance = sum(performance) / len(performance) # Compute average performance\n",
    "    return average_performance, performance\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    environment_configurations = [\n",
    "        ({\"A\":\"dirty\", \"B\":\"dirty\"}, \"A\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"clean\"}, \"A\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"dirty\"}, \"A\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"clean\"}, \"A\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"dirty\"}, \"B\"),\n",
    "        ({\"A\":\"dirty\", \"B\":\"clean\"}, \"B\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"dirty\"}, \"B\"),\n",
    "        ({\"A\":\"clean\", \"B\":\"clean\"}, \"B\"),\n",
    "    ]\n",
    "\n",
    "    sleep = 1\n",
    "    num_simulations = 4\n",
    "    average_performance, performance = simulate(environment_configurations, num_simulations, sleep)\n",
    "    print(f\"Average Performance: {average_performance}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP/RGNaTU9eLfWPb2lam7FS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
